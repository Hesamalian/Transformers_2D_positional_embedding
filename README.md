# Transformers with self attention and 2D positional embedding

This is a PyTorch implementation for a self-attention neural scorer with 2D positional encoding.
The model is mentioned in this [paper](https://aclanthology.org/2020.acl-main.580.pdf) and a the training sample is generated from ICDAR 2019 challenge  that can be found here: https://github.com/Michael-Xiu/ICDAR-SROIE .

--------

### Task

This is about the task of extracting structured information from form-like documents using a learned representation of an extraction candidate. Form-like documents like invoices, purchase orders, tax forms and insurance.

--------
